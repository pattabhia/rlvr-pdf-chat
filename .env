# Qdrant - local default
QDRANT_HOST=localhost
QDRANT_PORT=6333
QDRANT_COLLECTION_NAME=pdf_documents
QDRANT_PROFILE=local  # local | cloud | auto

# Qdrant Cloud (optional profile)
QDRANT_URL=
QDRANT_API_KEY=

# LLM Backend Configuration
LLM_BACKEND=ollama  # ollama | aws_endpoint | huggingface_endpoint

# Ollama - local LLM
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=llama3.2:3b

# AWS Endpoint Configuration (for future use after DPO training)
# Uncomment and configure after training your custom model
# LLM_BACKEND=aws_endpoint
# AWS_ENDPOINT_URL=https://your-model.sagemaker.us-east-1.amazonaws.com/invocations
# AWS_ENDPOINT_API_KEY=your-api-key-here
# AWS_ENDPOINT_MODEL_NAME=custom-support-model-dpo-v1

# HuggingFace Endpoint Configuration (alternative)
# LLM_BACKEND=huggingface_endpoint
# HUGGINGFACE_ENDPOINT_URL=https://your-endpoint.aws.endpoints.huggingface.cloud
# HUGGINGFACE_API_TOKEN=hf_xxxxxxxxxxxxx
# HUGGINGFACE_MODEL_NAME=custom-support-model

# LangSmith (optional but recommended)
LANGCHAIN_TRACING_V2=true
LANGCHAIN_ENDPOINT=https://api.smith.langchain.com
LANGCHAIN_API_KEY=your-langsmith-api-key-here
LANGCHAIN_PROJECT=rlvr-automation

# Embeddings - LOCAL PROFILE (CPU-optimized, fast 384-dim)
# For RunPod/GPU: use .env.runpod (768-dim)
# For AWS custom model: use .env.aws
EMBEDDING_BACKEND=sentence
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
EMBEDDING_DIMENSION=384
QDRANT_COLLECTION_NAME=documents


# EMBEDDING_BACKEND=openai
# EMBEDDING_MODEL=text-embedding-3-small
# EMBEDDING_DIMENSION=1536
# QDRANT_COLLECTION_NAME=pdf_documents_openai_v1
# OPENAI_API_KEY=your-openai-api-key-here

# Chunking defaults
CHUNK_SIZE=600
CHUNK_OVERLAP=80

# Retrieval defaults
TOP_K_RESULTS=6

# Logging
LOG_LEVEL=INFO

# RAGAS Verification thresholds
FAITHFULNESS_THRESHOLD=0.7
RELEVANCY_THRESHOLD=0.7

# RAGAS Configuration
RAGAS_LLM_BACKEND=ollama  # ollama | openai | heuristic
# Use 'heuristic' to skip RAGAS and use fast heuristic scoring
# Use 'ollama' to use local Llama 3.2 (free but less accurate)
# Use 'openai' to use GPT-4o-mini (best accuracy, costs ~$0.0001/evaluation)

# DPO Dataset Generation Thresholds
# RELAXED thresholds for testing - increase gradually for production
MIN_SCORE_DIFF=0.01          # Minimum score difference between best/worst answers (default: 0.3)
MIN_CHOSEN_SCORE=0.5         # Minimum score for chosen answer (default: 0.7)
ENABLE_QUALITY_FILTER=false  # Enable verbatim/quality checks (default: true)
